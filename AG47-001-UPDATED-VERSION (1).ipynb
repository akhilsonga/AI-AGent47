{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a9ea746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "import re\n",
    "import os\n",
    "import pyttsx3\n",
    "\n",
    "from groq import Groq\n",
    "if os.getenv(\"GROQ_API_KEY\") is None:\n",
    "    os.environ[\"GROQ_API_KEY\"] = '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'\n",
    "\n",
    "    \n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "import whisper\n",
    "from langdetect import detect\n",
    "from pytube import YouTube\n",
    "\n",
    "\n",
    "import tempfile\n",
    "\n",
    "#_________________________________________________________________________________________________________________\n",
    "\n",
    "#Youtube Search Video RAG with Vector DB\n",
    "\n",
    "def startfile(fn):\n",
    "    os.system('open %s' % fn)\n",
    "\n",
    "def create_and_open_txt(text, filename):\n",
    "    # Create and write the text to a txt file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(text)\n",
    "    startfile(filename)\n",
    "\n",
    "\n",
    "def delete_audio_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"Audio file {file_path} deleted successfully.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting audio file: {e}\")\n",
    "\n",
    "    \n",
    "def youtube_audio_text(url, path):\n",
    "    yt = YouTube(url)\n",
    "    audio_stream = yt.streams.filter(only_audio=True).first()\n",
    "    \n",
    "    output_path = path #r\"C:\\Users\\akhil\\Downloads\\YoutubeAudios\"\n",
    "    filename = \"audio.mp3\"\n",
    "    audio_stream.download(output_path=output_path, filename=filename)\n",
    "\n",
    "    print(f\"Audio downloaded to {output_path}\\{filename}\")\n",
    "\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(path + \"\\\\audio.mp3\")\n",
    "    transcribed_text = result[\"text\"]\n",
    "    #print(transcribed_text)\n",
    "\n",
    "    # language = detect(transcribed_text)\n",
    "    # print(f\"Detected language: {language}\")\n",
    "    delete_audio_file(path + \"\\\\audio.mp3\")\n",
    "    \n",
    "    create_and_open_txt(transcribed_text, path + \"\\\\output_Text.txt\")\n",
    "\n",
    "\n",
    "def Youtube_RAG(model, path):\n",
    "    llm = Ollama(model=\"mistral\", request_timeout=30.0)\n",
    "\n",
    "    #inp = input(\"enter 1 - Hugging Face Embedding \\n2 - OpenAI Embedding\")\n",
    "    inp = 1\n",
    "    if inp == 1:\n",
    "        #\n",
    "        Settings.embed_model = HuggingFaceEmbedding(model_name=\"flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\")\n",
    "\n",
    "\n",
    "    #Settings.llm = Ollama(model=\"mistral\", request_timeout=200.0)\n",
    "    Settings.llm = Ollama(model=model, request_timeout=200.0)\n",
    "    \n",
    "    documents = SimpleDirectoryReader(path).load_data()\n",
    "    sen_split=TokenTextSplitter()\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=[sen_split]\n",
    "    )\n",
    "    nodes=pipeline.run(show_progress=True,documents=documents, in_place=True)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        documents, transformations=[sen_split]\n",
    "    )\n",
    "    index.storage_context.persist(persist_dir=\"./indexDB\")\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=\"./indexDB\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(\"Summary of the Document\")\n",
    "    print(response)\n",
    "    return response\n",
    "    \n",
    "#     while True:\n",
    "#         #\n",
    "#         user_input = input(\"Enter 'stop' to end: \")\n",
    "#         if user_input.lower() == 'stop':\n",
    "#             print(\"Stopping the loop.\")\n",
    "#             break\n",
    "#         else:\n",
    "#             response = query_engine.query(user_input)\n",
    "#             print()\n",
    "#             print(response)\n",
    "        \n",
    "\n",
    "def youtube(url):\n",
    "    path = tempfile.mkdtemp()\n",
    "#     path = \"C:\\\\Users\\\\akhil\\\\Downloads\\\\YOUTUBE_VIDEO_SCRPT_WRITTER\\\\Folder\"\n",
    "    #url = input(\"Enter the YouTube video URL: \")\n",
    "    youtube_audio_text(url, path)\n",
    "    #model_id = input(\"Enter the model you want to use: 1 - Mistral, 2- Codellama 13B, 3 - llava\")\n",
    "    model_id = 1\n",
    "    if model_id == 1:\n",
    "        response = Youtube_RAG(\"mistral\", path)\n",
    "    elif model_id == 2:\n",
    "        response = Youtube_RAG(\"codellama:13b\", path)\n",
    "#     elif model_id == 3:\n",
    "#         Youtube_RAG(\"codellama:13b\")\n",
    "    return response\n",
    "\n",
    "#_________________________________________________________________________________________________________________\n",
    "    \n",
    "    \n",
    "#Not using Groq Max Tokens Completed for Today\n",
    "def O_LLM_GroQ(query):\n",
    "    client = Groq(\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "        #model=\"gemma-7b-it\",\n",
    "        temperature = 0,\n",
    "    )\n",
    "\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    return response\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "#Gemini 1.0 pro, good not great need to test on 1.5 pro in google hackathon\n",
    "def O_LLM(query):\n",
    "    Gemini_API = \"AIzaSyATwhUa9DSZrCAphxwHXPLEHWCZ-IDptT8\"\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    genai.configure(api_key=Gemini_API)\n",
    "    response = model.generate_content(query)\n",
    "    resp = response.text\n",
    "   # print(response.text)\n",
    "    return resp\n",
    "\n",
    "\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*(.*)'\n",
    "    output_pattern = r'Output \\d+:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text)\n",
    "    actions = re.findall(action_pattern, text)\n",
    "    outputs = re.findall(output_pattern, text)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n",
    "def extract_info(texts):\n",
    "    \"\"\"\n",
    "    This function extracts tools and inputs from a list of text strings.\n",
    "\n",
    "    Args:\n",
    "      texts: A list of strings containing instructions with tools and inputs in brackets.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary where keys are tools (e.g., \"Search\", \"Summarize\", \"Calculate\") \n",
    "      and values are corresponding inputs (e.g., \"funding received by Mistral Ai from investors\").\n",
    "    \"\"\"\n",
    "    tools = {}\n",
    "    for text in texts:\n",
    "        # Extract tool using regular expression\n",
    "        tool = re.findall(r'^\\w+', text)[0]\n",
    "\n",
    "        # Extract input using regular expression\n",
    "        inp = re.findall(r'\\[(.*?)\\]', text)[0]\n",
    "\n",
    "        # Add tool and input to the dictionary\n",
    "        tools[tool] = inp\n",
    "    return tools\n",
    "\n",
    "\n",
    "\n",
    "def duck_go(Keyword):\n",
    "    print(Keyword)\n",
    "    results = DDGS().text(Keyword, max_results=20)\n",
    "    bodies = [item['body'] for item in results]\n",
    "    paragraph = ' '.join(bodies)\n",
    "    return paragraph\n",
    "\n",
    "def Calculate(expression):\n",
    "    print(f\"Calculating: {expression}\")\n",
    "\n",
    "    \n",
    "import subprocess\n",
    "\n",
    "def execute_python(code):\n",
    "    #print(\"Code recieved for execution Terminal: \",code)\n",
    "    result = subprocess.run([\"python\", \"-c\", code], capture_output=True, text=True)\n",
    "    err = 0\n",
    "    # Check if there's an error\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error Found\")\n",
    "        err = 1\n",
    "        return result.stderr, err\n",
    "    else:\n",
    "        \n",
    "        output = result.stdout\n",
    "        return output, err\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def extract_text(input_string, option):\n",
    "    if option == 1:\n",
    "        pattern = r'\\```python(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        pattern = r'\\```(.*?)\\```'\n",
    "        matches = re.search(pattern, input_string, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches.group(1).strip()\n",
    "        else:\n",
    "            return None\n",
    "#------------------------------------------------------------------------------------------------\n",
    "def check_substring(main_string, substring):\n",
    "\n",
    "    if substring.lower() in main_string.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#------------------------------------------------------------------------------------------------\n",
    "Error_Counter = 0\n",
    "\n",
    "def code_processing(answer):\n",
    "    #answer = O_LLM(query)\n",
    "    main_string = answer\n",
    "    substring = \"```python\"\n",
    "    substring_sub = \"```\"\n",
    "    print(\"\\n\\n\")\n",
    "    if check_substring(main_string, substring_sub):\n",
    "        #print(\"```, FOUND PREPROCESSING... \")\n",
    "        \n",
    "        if check_substring(main_string, substring):\n",
    "            #print(\"```python, FOUND PREPROCESSING... \")\n",
    "            input_string =  answer\n",
    "            extracted_text = extract_text(input_string, 1)\n",
    "            \n",
    "            if extracted_text:\n",
    "                answer = extracted_text\n",
    "                #print(\"Extracted Text: \\n\", answer)\n",
    "                code = answer\n",
    "            else:\n",
    "                #print(\"No text found between ``` and ```.\")\n",
    "                code = answer\n",
    "        else:\n",
    "            print(\"\")\n",
    "            if check_substring(main_string, substring_sub):\n",
    "                print(\"```python, FOUND PREPROCESSING... \")\n",
    "                input_string =  answer\n",
    "                extracted_text = extract_text(input_string, 0)\n",
    "\n",
    "                if extracted_text:\n",
    "                    answer = extracted_text\n",
    "                    #print(\"Extracted Text: \\n\", answer)\n",
    "                    code = answer\n",
    "                else:\n",
    "                    print(\"No text found between ``` and ```.\")\n",
    "                    code = answer\n",
    "            \n",
    "    else:\n",
    "        print(\"```python ,NOT FOUND\")\n",
    "        code = answer\n",
    "    print(\"Code Extracted: \",code)\n",
    "    code_to_execute = code    \n",
    "    result, err = execute_python(code_to_execute)\n",
    "    if err == 0:\n",
    "        print(\"Returning Result to Prompt: \", result)\n",
    "        Error_Counter = 0\n",
    "        return result\n",
    "    else:\n",
    "        Code_error_recur(code_to_execute, result)\n",
    "\n",
    "        \n",
    "\n",
    "def Code_error_recur(code_to_execute, result):\n",
    "    Error_Counter = Error_Counter + 1\n",
    "    Error_query = \"Code: \" + code_to_execute + \"\\n Error: \" + result + \"\\n Dont add any comments and always write code under these tags '```python' and '```' \" \n",
    "    resp = O_LLM(Error_query)\n",
    "    code_processing(resp)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "    \n",
    "\n",
    "def Voice(voice_response):\n",
    "    text = voice_response\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 190)    # Speed percent (can go over 100)\n",
    "    engine.setProperty('volume', 0.9)  # Volume 0-1\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "    return \"Speaking completed\"\n",
    "    \n",
    "#Afterwards Update match with elif\n",
    "def handle_request(data, thought):\n",
    "    #\n",
    "    if \"Search\" in data:\n",
    "        output = duck_go(data[\"Search\"])\n",
    "        param = data[\"Search\"]\n",
    "        print(\"In DuckDuckGo Search Question:\",thought)\n",
    "        prompt = f\"Answer this question by reading the reference \\n Question: {thought}\\n\\n\\n Reference: {output}\"\n",
    "        output = O_LLM(prompt)\n",
    "        return output\n",
    "    elif \"Calculate\" in data:\n",
    "        output = Calculate(data[\"Calculate\"])\n",
    "        return output\n",
    "    elif \"Python\" in data:\n",
    "        output = code_processing(data[\"Python\"])\n",
    "        return output\n",
    "    elif \"Voice\" in data:\n",
    "        output = Voice(data[\"Voice\"])\n",
    "        return output\n",
    "    elif \"Youtube\" in data:\n",
    "        output = youtube(data[\"Youtube\"])\n",
    "        return output\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid key. Please use 'Search' or 'Calculate'\")\n",
    "\n",
    "        \n",
    "def convert_list_to_dict(data):\n",
    "    result = {}\n",
    "    for item in data:\n",
    "        try:\n",
    "            key, value = item.split('[', 1)\n",
    "            value = value.rsplit(']', 1)[0].strip()  # Get text from beginning to last ']'\n",
    "            if value:  # Check if value is not empty (null)\n",
    "                result[key.strip()] = value\n",
    "        except ValueError:\n",
    "            continue  # Skip to the next iteration if splitting fails\n",
    "    return result\n",
    "\n",
    "def extract_thoughts_actions_output(text):\n",
    "    thoughts = []\n",
    "    actions = []\n",
    "    outputs = []\n",
    "\n",
    "    thought_pattern = r'Thought \\d+:\\s*(.*)'\n",
    "    action_pattern = r'Action \\d+:\\s*([\\s\\S]*?)(?=(?:Thought \\d+|$))'\n",
    "    output_pattern = r'output:\\s*(.*)'\n",
    "\n",
    "    # Extract Thoughts, Actions, and Output\n",
    "    thoughts = re.findall(thought_pattern, text, re.IGNORECASE)\n",
    "    action_matches = re.findall(action_pattern, text, re.IGNORECASE)\n",
    "    actions = ['\\n'.join(action.strip().split('\\n')) for action in action_matches]\n",
    "    outputs = re.findall(output_pattern, text, re.IGNORECASE)\n",
    "\n",
    "    return thoughts, actions, outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847d43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f643eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Consider yourself as a developer and break down this complex Task into multiple simple tasks as Thoughts.\n",
      "\n",
      "Task: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Thought 2: By understanding Output 1, I need to answer the Question\n",
      "Thought 3: By Understanding Output 2, Write a python code to check how many letters does the company have?\n",
      "Thought 4: Now With all the information, I will write the Final Answer. \n",
      "\n",
      "Task:  Search Internt, about markerting budget of PUMA and use Youtube [https://www.youtube.com/watch?v=-gWVt0GyW1w] tool and tell about the youtube video it \n",
      "Build simple multiple Thoughts for this Task and use Search and Youtube tool\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools available to use: Search[Text to search in the internet], Calculate[Expression to calculate], Python[```python <Full Python code>```], Voice[Text to speech], Youtube[<Youtube URL>]\n",
      "Question: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Thought 2: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 2: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prompt\n",
    "Task = \" Search Internt, who are 'All the ambassador of PUMA' and list all individual ambassador with followers count on instagram\"\n",
    "Task = \" Search Internt, about markerting budget of PUMA and use Youtube [https://www.youtube.com/watch?v=-gWVt0GyW1w] tool and tell about the youtube video it \"\n",
    "\n",
    "Example_prompt_thoughts = \"\"\"\n",
    "Consider yourself as a developer and break down this complex Task into multiple simple tasks as Thoughts.\n",
    "\n",
    "Task: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
    "Thought 1: First I need to search what is the company building of Q* AGI\n",
    "Thought 2: By understanding Output 1, I need to answer the Question\n",
    "Thought 3: By Understanding Output 2, Write a python code to check how many letters does the company have?\n",
    "Thought 4: Now With all the information, I will write the Final Answer. \n",
    "\"\"\"\n",
    "Task_promp_thoughts = f\"\"\"\n",
    "{Example_prompt_thoughts}\n",
    "Task: {Task}\n",
    "Build simple multiple Thoughts for this Task and use Search and Youtube tool\n",
    "\"\"\"\n",
    "print(Task_promp_thoughts)\n",
    "\n",
    "\n",
    "\n",
    "Example_prompt_Actions = \"\"\"\n",
    "Tools available to use: Search[Text to search in the internet], Calculate[Expression to calculate], Python[```python <Full Python code>```], Voice[Text to speech], Youtube[<Youtube URL>]\n",
    "Question: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
    "Thought 1: First I need to search what is the company building of Q* AGI\n",
    "Action 1:Search[company of Q* AGI]\n",
    "Thought 2: Write a python code to check how many does 'OpenAI' have?\n",
    "Action 2: Python[```python\n",
    "text = \"Open AI\"\n",
    "letter_count = sum(1 for char in text if char.isalpha())\n",
    "print(letter_count)\n",
    "```]\n",
    "\"\"\"\n",
    "print(\"\\n\\n\")\n",
    "print(Example_prompt_Actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30e96fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought 1: First I need to search about marketing budget of PUMA\n",
      "Thought 2: By understanding Output 1, I will open Youtube link [https://www.youtube.com/watch?v=-gWVt0GyW1w]\n",
      "Thought 3: By Watching youtube Video, I need to answer the Question\n",
      "\n",
      "Task:  Find out which company invented the transistor, and what is the date format of the date they invented the transistor?\n",
      "\n",
      "Thought 1: First I need to search which company invented the transistor\n",
      "Thought 2: By understanding Output 1, I need to extract the date format of the date they invented the transistor\n"
     ]
    }
   ],
   "source": [
    "def To_do_list(text):\n",
    "    thoughts = re.findall(r'(?i)(?<=thought\\s)\\d+:\\s(.+)', text)\n",
    "    return thoughts\n",
    "\n",
    "def Main_thread_TL(Task_promp_thoughts):\n",
    "    #\n",
    "    resp = O_LLM(Task_promp_thoughts)\n",
    "    print(resp)\n",
    "    thoughts_list = To_do_list(resp)\n",
    "    return thoughts_list\n",
    "    \n",
    "thoughts_list = Main_thread_TL(Task_promp_thoughts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6937b751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First I need to search about marketing budget of PUMA',\n",
       " 'By understanding Output 1, I will open Youtube link [https://www.youtube.com/watch?v=-gWVt0GyW1w]',\n",
       " 'By Watching youtube Video, I need to answer the Question',\n",
       " 'First I need to search which company invented the transistor',\n",
       " 'By understanding Output 1, I need to extract the date format of the date they invented the transistor']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thoughts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34175433",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tools available to use: Search[Text to search in the internet], Calculate[Expression to calculate], Python[```python <Full Python code>```], Voice[Text to speech], Youtube[<Youtube URL>]\n",
      "Question: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Thought 2: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 2: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Task:  Search Internt, about markerting budget of PUMA and use Youtube [https://www.youtube.com/watch?v=-gWVt0GyW1w] tool and tell about the youtube video it \n",
      " Thought: First I need to search about marketing budget of PUMA\n",
      "Write an simple Action with correct syntax:\n",
      "Action 1: Search[marketing budget of PUMA]\n",
      "______________________________________\n",
      "\n",
      "\n",
      "All Action tools found: (List)  {'Search': 'marketing budget of PUMA'}\n",
      "Last Key value: (Dictionary)  {'Search': 'marketing budget of PUMA'}\n",
      "marketing budget of PUMA\n",
      "In DuckDuckGo Search Question: First I need to search about marketing budget of PUMA\n",
      "RESULY:\n",
      " In 2021, Puma spent 1.31 billion euros on marketing, which was an increase from the 2020 budget of 1.05 billion euros.\n",
      "\n",
      "Tools available to use: Search[Text to search in the internet], Calculate[Expression to calculate], Python[```python <Full Python code>```], Voice[Text to speech], Youtube[<Youtube URL>]\n",
      "Question: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Thought 2: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 2: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Task:  Search Internt, about markerting budget of PUMA and use Youtube [https://www.youtube.com/watch?v=-gWVt0GyW1w] tool and tell about the youtube video it \n",
      " Thought: By understanding Output 1, I will open Youtube link [https://www.youtube.com/watch?v=-gWVt0GyW1w]\n",
      "Write an simple Action with correct syntax:\n",
      "Action 1: Youtube[https://www.youtube.com/watch?v=-gWVt0GyW1w]\n",
      "______________________________________\n",
      "\n",
      "\n",
      "All Action tools found: (List)  {'Youtube': 'https://www.youtube.com/watch?v=-gWVt0GyW1w'}\n",
      "Last Key value: (Dictionary)  {'Youtube': 'https://www.youtube.com/watch?v=-gWVt0GyW1w'}\n",
      "Audio downloaded to C:\\Users\\akhil\\AppData\\Local\\Temp\\tmpd3e52qnq\\audio.mp3\n",
      "Audio file C:\\Users\\akhil\\AppData\\Local\\Temp\\tmpd3e52qnq\\audio.mp3 deleted successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1f37ee515a4a17aceb6458ad819e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The document discusses an individual's experience using Changi PT (Changi Picnic Time), an AI tool for editing images and generating new ones. The person was able to turn a shitsu (a breed of dog) into a wizard with a cloak, hat, and glowing green eyes, but noted that the edits weren't always consistent with the rest of the image or the art style. They also attempted to edit text in an image, but found that Changi PT struggled with this task. The person then moved on to editing two images side by side: one of a 3D lemon character and another of a peach floating on a tube in the ocean. They noted that Changi PT had trouble placing the images correctly and fixing text, but was effective at fixing hands and adding details. The individual also mentioned that they could generate text using Changi PT, but it wasn't perfect. They compared Changi PT to another AI tool called Videogram AI, noting that Videogram was better for text generation but less effective for image editing overall. Finally, the person discussed some accessibility features of Changi PT and mentioned an open source alternative called Brushnet. They ended the document by asking for thoughts on OpenAI's approach to image generation and encouraging viewers to check out their Twitter and Discord server.\n",
      "RESULY:\n",
      "  The document discusses an individual's experience using Changi PT (Changi Picnic Time), an AI tool for editing images and generating new ones. The person was able to turn a shitsu (a breed of dog) into a wizard with a cloak, hat, and glowing green eyes, but noted that the edits weren't always consistent with the rest of the image or the art style. They also attempted to edit text in an image, but found that Changi PT struggled with this task. The person then moved on to editing two images side by side: one of a 3D lemon character and another of a peach floating on a tube in the ocean. They noted that Changi PT had trouble placing the images correctly and fixing text, but was effective at fixing hands and adding details. The individual also mentioned that they could generate text using Changi PT, but it wasn't perfect. They compared Changi PT to another AI tool called Videogram AI, noting that Videogram was better for text generation but less effective for image editing overall. Finally, the person discussed some accessibility features of Changi PT and mentioned an open source alternative called Brushnet. They ended the document by asking for thoughts on OpenAI's approach to image generation and encouraging viewers to check out their Twitter and Discord server.\n",
      "\n",
      "Tools available to use: Search[Text to search in the internet], Calculate[Expression to calculate], Python[```python <Full Python code>```], Voice[Text to speech], Youtube[<Youtube URL>]\n",
      "Question: Which company building Q* AGI? And tell me check how many letters does that company name have?\n",
      "Thought 1: First I need to search what is the company building of Q* AGI\n",
      "Action 1:Search[company of Q* AGI]\n",
      "Thought 2: Write a python code to check how many does 'OpenAI' have?\n",
      "Action 2: Python[```python\n",
      "text = \"Open AI\"\n",
      "letter_count = sum(1 for char in text if char.isalpha())\n",
      "print(letter_count)\n",
      "```]\n",
      "Task:  Search Internt, about markerting budget of PUMA and use Youtube [https://www.youtube.com/watch?v=-gWVt0GyW1w] tool and tell about the youtube video it \n",
      " Thought: By Watching youtube Video, I need to answer the Question\n",
      "Write an simple Action with correct syntax:\n",
      "Action: Youtube[https://www.youtube.com/watch?v=-gWVt0GyW1w]\n",
      "______________________________________\n",
      "\n",
      "\n",
      "All Action tools found: (List)  {}\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "# thoughts_list = ['First, need to understand the data in the sales.csv dataset and figure out what insights can be extracted from it.', 'Once I have a good understanding of the data, I can start to develop a machine learning model for predictive analytics.', 'I can use the insights I extracted from the data to select the most appropriate machine learning algorithm for the task.', 'Once I have selected an algorithm, I can train the model on the data and evaluate its performance.', 'Finally, I can use the trained model to make predictions on new data.']\n",
    "\n",
    "def Main_thread(thoughts_list):\n",
    "    #\n",
    "    #resp = O_LLM(Task_promp_thoughts)\n",
    "    #print(resp)\n",
    "    #thoughts_list = To_do_list(resp)\n",
    "    num = 0\n",
    "    resp_list = []\n",
    "    for i in thoughts_list[:3]:\n",
    "        num = num + 1 \n",
    "        Action_prompt = Example_prompt_Actions + \"Task: \"+Task +  \"\\n Thought: \"+ i + \"\\nWrite an simple Action with correct syntax:\"\n",
    "        print(Action_prompt)\n",
    "        resp = O_LLM(Action_prompt)\n",
    "        print(resp)\n",
    "        resp_list.append(resp)\n",
    "        print(\"______________________________________\\n\\n\")\n",
    "        try:\n",
    "            thoughts_list, actions_list, output_list = extract_thoughts_actions_output(resp)\n",
    "            actions_tools_dic = convert_list_to_dict(actions_list)\n",
    "            print(\"All Action tools found: (List) \",actions_tools_dic)\n",
    "\n",
    "            main_dict = actions_tools_dic\n",
    "            last_key_value = {list(main_dict.keys())[-1]: main_dict[list(main_dict.keys())[-1]]}\n",
    "\n",
    "            print(\"Last Key value: (Dictionary) \",last_key_value)\n",
    "            result = handle_request(last_key_value, i)\n",
    "            print(\"RESULY:\\n\",result)\n",
    "#             break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "Main_thread(thoughts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1a961",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cd5196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2bdf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d7d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d02d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d000bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7659d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbcc52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_K",
   "language": "python",
   "name": "openai_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
